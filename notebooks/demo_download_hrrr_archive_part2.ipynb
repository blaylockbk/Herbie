{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Brian Blaylock**  \n",
    "**June 25, 2020**  \n",
    "\n",
    "üåê HRRR Archive Website: http://hrrr.chpc.utah.edu/  \n",
    "üöë Support: atmos-mesowest@lists.utah.edu  \n",
    "üìß Brian Blaylock: blaylockbk@gmail.com  \n",
    "‚úí Citation this details:\n",
    "> Blaylock B., J. Horel and S. Liston, 2017: Cloud Archiving and Data Mining of High Resolution Rapid Refresh Model Output. Computers and Geosciences. 109, 43-50. https://doi.org/10.1016/j.cageo.2017.08.005\n",
    "\n",
    "---\n",
    "\n",
    "# üèó HRRR Download Demo: Part 2\n",
    "## How to download a **subset** of variables from a HRRR file\n",
    "\n",
    "- [Part 1: How to download a bunch of HRRR grib2 files (full file)](./demo_download_hrrr_archive_part1.ipynb)\n",
    "- [Part 2: How to download a subset of variables from a HRRR file](./demo_download_hrrr_archive_part2.ipynb)\n",
    "- [Part 3: A function that can download many full files, or subset of files](./demo_download_hrrr_archive_part3.ipynb)\n",
    "- [Part 4: Opening GRIB2 files in Python with xarray and cfgrib](./demo_download_hrrr_archive_part4.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "As noted in **Part 1**, HRRR GRIB2 files can be downloaded from the [University of Utah's HRRR archive](http://hrrr.chpc.utah.edu/) on the CHPC Pando archive system. You may also get HRRR GRIB2 files from the [NOAA Operational Model Archive and Distribution System (NOMADS)](https://nomads.ncep.noaa.gov/), but only for the today's and yesterday's runs. In **Part 1** I showed you a function that can may be used to download many full GRIB2 files.\n",
    "\n",
    "This notebook shows how to download **just select \"fields\" of a GRIB2 file** instead of the full file. We have to use the `cURL` command line program to download a range of bytes from a file. Fortunatly, `cURL` should be included in your Anaconda environment.\n",
    "\n",
    "### Background Info\n",
    "\n",
    "You first need to know how GRIB files work. The GRIB file format is made up of gridded binary \"fields\" stacked on top of one another. A GRIB \"field\" contains the information for a single variable at a certain level. We can target one or more of these fields in the file and just download the layers we want by downloading a *range of bytes* from the file. An \"index\" or `.idx` file has a list of GRIB messages that tell us what data is on each level and *what the beginning byte is for each field*.\n",
    "\n",
    "\n",
    "![image1](./images/GRIB2_file_cURL.png)\n",
    "\n",
    "You should know that it is not possible to subset the file download based on geographic region. The reason is because the byte location for specific grid points are not known, just the first and last byte of the variable \"field\".\n",
    "\n",
    "---\n",
    "\n",
    "Let's start by importing some modules we will use..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re              # Used to search for a string in a line\n",
    "import requests        # Used to check if a URL exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the URL for a HRRR GRIB2 file located on Pando, we need to read the `.idx` file to find the locatio of the beginning byte for each of the variables. The URL for a file's `.idx` file is just the file URL with '.idx' append to the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2.idx'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example file\n",
    "url = 'https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2'\n",
    "idx = url + '.idx'\n",
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets read the `.idx` file and look at the first ten lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1:0:d=2020062401:REFC:entire atmosphere:17 hour fcst:',\n",
       " '2:490289:d=2020062401:RETOP:cloud top:17 hour fcst:',\n",
       " '3:681173:d=2020062401:VIL:entire atmosphere:17 hour fcst:',\n",
       " '4:943024:d=2020062401:VIS:surface:17 hour fcst:',\n",
       " '5:2286009:d=2020062401:REFD:1000 m above ground:17 hour fcst:',\n",
       " '6:2547950:d=2020062401:REFD:4000 m above ground:17 hour fcst:',\n",
       " '7:2723918:d=2020062401:REFD:263 K level:17 hour fcst:',\n",
       " '8:2901079:d=2020062401:GUST:surface:17 hour fcst:',\n",
       " '9:4074410:d=2020062401:UGRD:250 mb:17 hour fcst:',\n",
       " '10:4855103:d=2020062401:VGRD:250 mb:17 hour fcst:']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a request for the .idx file for the above URL\n",
    "r = requests.get(url+'.idx')\n",
    "\n",
    "# Check that the file exists. If there isn't an index, you will get a 404 error.\n",
    "if not r.ok: \n",
    "    print('Status Code:', r.status_code, r.reason)\n",
    "\n",
    "# Read the text lines of the request\n",
    "lines = r.text.split('\\n')\n",
    "\n",
    "# Just look at the first 10 lines\n",
    "lines[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see above that each line in the index file describes each GRIB \"field\" or \"grid\" in the file. Here is a break down of the 10th line...\n",
    "- `10` - The GRIB message number.\n",
    "- `4855103` - The beginning byte for this variable.\n",
    "- `d=2020062401` - The datetime the model was initialized YYYYMMDDHH.\n",
    "- `VGRD` - The GRIB variable short name.\n",
    "- `250 mb` - The level of the data.\n",
    "- `17 hour fcst` - The forecast lead time.\n",
    "\n",
    "![image2](./images/grib2_idx.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ‚ùì If this is the first time you have looked at GRIB messages, you might wonder what each of the abbreviated short variables names mean. [Here is an explaination of variables names in the HRRR files](http://home.chpc.utah.edu/~u0553130/Brian_Blaylock/HRRR_archive/hrrr_sfc_table_f00-f01.html). Also, [click here for a GRIB2 table used by NCEP](https://www.nco.ncep.noaa.gov/pmb/docs/on388/table2.html). \n",
    "\n",
    "To download a range of bytes, we need the beginning byte for the variable we want and the beginning byte for the next variable. \n",
    "\n",
    "We will define a string to look for in the file and loop over every line until we find the message for the \"fields\" we want to download. **Generally, you will define a search string based on the variable type and level you want.** \n",
    "\n",
    "I wrote the following line search loop to allow the use of *regular expressions*. What are regular experssions? [Here is a cheat sheet](https://link.medium.com/7rxduD2e06).\n",
    "\n",
    "For example: \n",
    "\n",
    "    search_this = 'TMP:500 mb'    # Temperature at the 500 mb variables\n",
    "    search_this = ':500 mb'       # All the 500 mb variables\n",
    "    search_this = 'SBT:'          # All Simulated brightness temperature\n",
    "    search_this = 'APCP'          # All accumulated precipiation\n",
    "    search_this = '.GRD:80 m'     # U and V wind components at 80 meters above ground\n",
    "    search_this = ':(U|V)GRD:'    # U and V wind components at all levels\n",
    "    search_this = ':(DPT|TMP):'   # Dew Point and Temperature at all levels\n",
    "    #get_variable = ':REFC:'      # Composite Reflectivity\n",
    "    #get_variable = ':surface:'   # All variables valid at the surface.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4074410-4855103': '9:4074410:d=2020062401:UGRD:250 mb:17 hour fcst:',\n",
       " '4855103-5621119': '10:4855103:d=2020062401:VGRD:250 mb:17 hour fcst:',\n",
       " '5621119-6409673': '11:5621119:d=2020062401:UGRD:300 mb:17 hour fcst:',\n",
       " '6409673-7182342': '12:6409673:d=2020062401:VGRD:300 mb:17 hour fcst:',\n",
       " '9396709-9988321': '16:9396709:d=2020062401:UGRD:500 mb:17 hour fcst:',\n",
       " '9988321-10587398': '17:9988321:d=2020062401:VGRD:500 mb:17 hour fcst:',\n",
       " '12910456-13516093': '21:12910456:d=2020062401:UGRD:700 mb:17 hour fcst:',\n",
       " '13516093-14130774': '22:13516093:d=2020062401:VGRD:700 mb:17 hour fcst:',\n",
       " '16569914-17195734': '26:16569914:d=2020062401:UGRD:850 mb:17 hour fcst:',\n",
       " '17195734-17825413': '27:17195734:d=2020062401:VGRD:850 mb:17 hour fcst:',\n",
       " '19521842-20158378': '30:19521842:d=2020062401:UGRD:925 mb:17 hour fcst:',\n",
       " '20158378-20789480': '31:20158378:d=2020062401:VGRD:925 mb:17 hour fcst:',\n",
       " '22524126-23158000': '34:22524126:d=2020062401:UGRD:1000 mb:17 hour fcst:',\n",
       " '23158000-23783838': '35:23158000:d=2020062401:VGRD:1000 mb:17 hour fcst:',\n",
       " '33201920-34396975': '55:33201920:d=2020062401:UGRD:80 m above ground:17 hour fcst:',\n",
       " '34396975-35543182': '56:34396975:d=2020062401:VGRD:80 m above ground:17 hour fcst:',\n",
       " '49201177-50402143': '71:49201177:d=2020062401:UGRD:10 m above ground:17 hour fcst:',\n",
       " '50402143-51546994': '72:50402143:d=2020062401:VGRD:10 m above ground:17 hour fcst:'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For this example, lets search for all U and V wind fields.\n",
    "search_this = ':(U|V)GRD:'\n",
    "\n",
    "# Search expression\n",
    "expr = re.compile(search_this)\n",
    "\n",
    "# Store the byte ranges we find for our variables in a dictionary\n",
    "#     {byte-range-as-string: line}\n",
    "byte_ranges = {}\n",
    "for n, line in enumerate(lines, start=1):\n",
    "    # n is the line number (starting from 1) so that when we call for \n",
    "    # `lines[n]` it will give us the next line. (Clear as mud??)\n",
    "    \n",
    "    # Use the compiled regular expression to search the line\n",
    "    if expr.search(line):   \n",
    "        # aka, if the line contains the string we are looking for...\n",
    "        \n",
    "        # Get the beginning byte in the line we found\n",
    "        parts = line.split(':')\n",
    "        rangestart = int(parts[1])\n",
    "        \n",
    "        # Get the beginning byte in the next line...\n",
    "        if n+1 < len(lines):\n",
    "            # ...if there is a next line\n",
    "            parts = lines[n].split(':')\n",
    "            rangeend = int(parts[1])\n",
    "        else:\n",
    "            # ...if there isn't a next line, then go to the end of the file.\n",
    "            rangeend = ''\n",
    "        \n",
    "        # Store the byte-range string in our dictionary, \n",
    "        # and keep the line information too so we can refer back to it.\n",
    "        byte_ranges[f'{rangestart}-{rangeend}'] = line\n",
    "\n",
    "# Now lets take a look at what we gathered...\n",
    "byte_ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the byte ranges for each line we want, lets download each item with `cURL`. Note that cURL is a command-line tool. We can execute a cURL statement with `os.system`. The downloaded content will be appended to the end of the file we create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'subset_20200624_hrrr.t01z.wrfsfcf17.grib2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What should we name the file we download the data into?\n",
    "\n",
    "# We want the filename to include the model run date (we can get that from the line information)\n",
    "runDate = list(byte_ranges.items())[0][1].split(':')[2][2:-2]\n",
    "\n",
    "# And we want to label the filename as a \"subset\"\n",
    "outFile = '_'.join(['subset', runDate, url.split('/')[-1]])\n",
    "\n",
    "\n",
    "# Ok, this file name looks good to me. It's unique and says what it is.\n",
    "outFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will a loop and cURL to download each \"field\" of the file we searched for..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on line 9:4074410:d=2020062401:UGRD:250 mb:17 hour fcst:\n",
      "I am executing this cURL command...\n",
      "  üíæ `curl -s --range 4074410-4855103 https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2 > subset_20200624_hrrr.t01z.wrfsfcf17.grib2`\n",
      "\n",
      "Working on line 10:4855103:d=2020062401:VGRD:250 mb:17 hour fcst:\n",
      "I am executing this cURL command...\n",
      "  üíæ `curl -s --range 4855103-5621119 https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2 >> subset_20200624_hrrr.t01z.wrfsfcf17.grib2`\n",
      "\n",
      "Working on line 11:5621119:d=2020062401:UGRD:300 mb:17 hour fcst:\n",
      "I am executing this cURL command...\n",
      "  üíæ `curl -s --range 5621119-6409673 https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2 >> subset_20200624_hrrr.t01z.wrfsfcf17.grib2`\n",
      "\n",
      "Working on line 12:6409673:d=2020062401:VGRD:300 mb:17 hour fcst:\n",
      "I am executing this cURL command...\n",
      "  üíæ `curl -s --range 6409673-7182342 https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2 >> subset_20200624_hrrr.t01z.wrfsfcf17.grib2`\n",
      "\n",
      "Working on line 16:9396709:d=2020062401:UGRD:500 mb:17 hour fcst:\n",
      "I am executing this cURL command...\n",
      "  üíæ `curl -s --range 9396709-9988321 https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2 >> subset_20200624_hrrr.t01z.wrfsfcf17.grib2`\n",
      "\n",
      "Working on line 17:9988321:d=2020062401:VGRD:500 mb:17 hour fcst:\n",
      "I am executing this cURL command...\n",
      "  üíæ `curl -s --range 9988321-10587398 https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2 >> subset_20200624_hrrr.t01z.wrfsfcf17.grib2`\n",
      "\n",
      "Working on line 21:12910456:d=2020062401:UGRD:700 mb:17 hour fcst:\n",
      "I am executing this cURL command...\n",
      "  üíæ `curl -s --range 12910456-13516093 https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2 >> subset_20200624_hrrr.t01z.wrfsfcf17.grib2`\n",
      "\n",
      "Working on line 22:13516093:d=2020062401:VGRD:700 mb:17 hour fcst:\n",
      "I am executing this cURL command...\n",
      "  üíæ `curl -s --range 13516093-14130774 https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2 >> subset_20200624_hrrr.t01z.wrfsfcf17.grib2`\n",
      "\n",
      "Working on line 26:16569914:d=2020062401:UGRD:850 mb:17 hour fcst:\n",
      "I am executing this cURL command...\n",
      "  üíæ `curl -s --range 16569914-17195734 https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2 >> subset_20200624_hrrr.t01z.wrfsfcf17.grib2`\n",
      "\n",
      "Working on line 27:17195734:d=2020062401:VGRD:850 mb:17 hour fcst:\n",
      "I am executing this cURL command...\n",
      "  üíæ `curl -s --range 17195734-17825413 https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2 >> subset_20200624_hrrr.t01z.wrfsfcf17.grib2`\n",
      "\n",
      "Working on line 30:19521842:d=2020062401:UGRD:925 mb:17 hour fcst:\n",
      "I am executing this cURL command...\n",
      "  üíæ `curl -s --range 19521842-20158378 https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2 >> subset_20200624_hrrr.t01z.wrfsfcf17.grib2`\n",
      "\n",
      "Working on line 31:20158378:d=2020062401:VGRD:925 mb:17 hour fcst:\n",
      "I am executing this cURL command...\n",
      "  üíæ `curl -s --range 20158378-20789480 https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2 >> subset_20200624_hrrr.t01z.wrfsfcf17.grib2`\n",
      "\n",
      "Working on line 34:22524126:d=2020062401:UGRD:1000 mb:17 hour fcst:\n",
      "I am executing this cURL command...\n",
      "  üíæ `curl -s --range 22524126-23158000 https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2 >> subset_20200624_hrrr.t01z.wrfsfcf17.grib2`\n",
      "\n",
      "Working on line 35:23158000:d=2020062401:VGRD:1000 mb:17 hour fcst:\n",
      "I am executing this cURL command...\n",
      "  üíæ `curl -s --range 23158000-23783838 https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2 >> subset_20200624_hrrr.t01z.wrfsfcf17.grib2`\n",
      "\n",
      "Working on line 55:33201920:d=2020062401:UGRD:80 m above ground:17 hour fcst:\n",
      "I am executing this cURL command...\n",
      "  üíæ `curl -s --range 33201920-34396975 https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2 >> subset_20200624_hrrr.t01z.wrfsfcf17.grib2`\n",
      "\n",
      "Working on line 56:34396975:d=2020062401:VGRD:80 m above ground:17 hour fcst:\n",
      "I am executing this cURL command...\n",
      "  üíæ `curl -s --range 34396975-35543182 https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2 >> subset_20200624_hrrr.t01z.wrfsfcf17.grib2`\n",
      "\n",
      "Working on line 71:49201177:d=2020062401:UGRD:10 m above ground:17 hour fcst:\n",
      "I am executing this cURL command...\n",
      "  üíæ `curl -s --range 49201177-50402143 https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2 >> subset_20200624_hrrr.t01z.wrfsfcf17.grib2`\n",
      "\n",
      "Working on line 72:50402143:d=2020062401:VGRD:10 m above ground:17 hour fcst:\n",
      "I am executing this cURL command...\n",
      "  üíæ `curl -s --range 50402143-51546994 https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2 >> subset_20200624_hrrr.t01z.wrfsfcf17.grib2`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (byteRange, line) in enumerate(byte_ranges.items()):\n",
    "    print('Working on line', line)\n",
    "    \n",
    "    if i == 0:\n",
    "        # If we are working on the first item, overwrite the existing file or create a new one.\n",
    "        curl = f'curl -s --range {byteRange} {url} > {outFile}'\n",
    "    else:\n",
    "        # If we are working on not the first item, append the existing file.\n",
    "        curl = f'curl -s --range {byteRange} {url} >> {outFile}'\n",
    "    \n",
    "    print('I am executing this cURL command...')\n",
    "    print(f'  üíæ `{curl}`\\n')\n",
    "    os.system(curl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the file we just created with `wgrib2`...You will see that it is a valid GRIB2 file with data in it. \n",
    "\n",
    "> Note: `wgrib2` is only available for Linux machines (you could install it on Windows if you want a big headache). If it isn't installed in your environment, you can download it via conda install. `conda install -c conda-forge wgrib2`. If you are on a Windows PC, don't sweat this part...there are other ways to look at a GRIB2 file (like with pygrib or xarray)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:0:d=2020062401:UGRD:250 mb:17 hour fcst:\n",
      "2:780694:d=2020062401:VGRD:250 mb:17 hour fcst:\n",
      "3:1546711:d=2020062401:UGRD:300 mb:17 hour fcst:\n",
      "4:2335266:d=2020062401:VGRD:300 mb:17 hour fcst:\n",
      "5:3107936:d=2020062401:UGRD:500 mb:17 hour fcst:\n",
      "6:3699549:d=2020062401:VGRD:500 mb:17 hour fcst:\n",
      "7:4298627:d=2020062401:UGRD:700 mb:17 hour fcst:\n",
      "8:4904265:d=2020062401:VGRD:700 mb:17 hour fcst:\n",
      "9:5518947:d=2020062401:UGRD:850 mb:17 hour fcst:\n",
      "10:6144768:d=2020062401:VGRD:850 mb:17 hour fcst:\n",
      "11:6774448:d=2020062401:UGRD:925 mb:17 hour fcst:\n",
      "12:7410985:d=2020062401:VGRD:925 mb:17 hour fcst:\n",
      "13:8042088:d=2020062401:UGRD:1000 mb:17 hour fcst:\n",
      "14:8675963:d=2020062401:VGRD:1000 mb:17 hour fcst:\n",
      "15:9301802:d=2020062401:UGRD:80 m above ground:17 hour fcst:\n",
      "16:10496858:d=2020062401:VGRD:80 m above ground:17 hour fcst:\n",
      "17:11643066:d=2020062401:UGRD:10 m above ground:17 hour fcst:\n",
      "18:12844033:d=2020062401:VGRD:10 m above ground:17 hour fcst:\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wgrib2 ./subset_20200624_hrrr.t01z.wrfsfcf17.grib2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Put it all together\n",
    "This next part is that same thing as above, but puts it together into a function you can use to download parts of a HRRR GRIB2 file from a URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re              # Used to search for a string in a line\n",
    "import requests        # Used to check if a URL exists\n",
    "\n",
    "def download_HRRR_subset(url, searchString, SAVEDIR='./', dryrun=False):\n",
    "    \"\"\"\n",
    "    Download a subset of GRIB fields from a HRRR file.\n",
    "    \n",
    "    This assumes there is an index (.idx) file available for the file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : string\n",
    "        The URL for the HRRR file you are trying to download. There must be an \n",
    "        index file for the GRIB2 file. For example, if \n",
    "        ``url='https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2'``,\n",
    "        then ``https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2.idx``\n",
    "        must also exist on the server.\n",
    "    searchString : str\n",
    "        The string you are looking for in each line of the index file. \n",
    "        Take a look at the \n",
    "        .idx file at https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2.idx\n",
    "        to get familiar with what is in each line.\n",
    "        Also look at this webpage: http://hrrr.chpc.utah.edu/HRRR_archive/hrrr_sfc_table_f00-f01.html\n",
    "        for additional details.**You should focus on the variable and level \n",
    "        field for your searches**.\n",
    "        \n",
    "        You may use regular expression syntax to customize your search. \n",
    "        Check out this regulare expression cheatsheet:\n",
    "        https://link.medium.com/7rxduD2e06\n",
    "        \n",
    "        Here are a few examples that can help you get started\n",
    "        \n",
    "        ================ ===============================================\n",
    "        ``searchString`` Messages that will be downloaded\n",
    "        ================ ===============================================\n",
    "        ':TMP:2 m'       Temperature at 2 m.\n",
    "        ':TMP:'          Temperature fields at all levels.\n",
    "        ':500 mb:'       All variables on the 500 mb level.\n",
    "        ':APCP:'         All accumulated precipitation fields.\n",
    "        ':UGRD:10 m:'    U wind component at 10 meters.\n",
    "        ':(U|V)GRD:'     U and V wind component at all levels.\n",
    "        ':.GRD:'         (Same as above)\n",
    "        ':(TMP|DPT):'    Temperature and Dew Point for all levels .\n",
    "        ':(TMP|DPT|RH):' TMP, DPT, and Relative Humidity for all levels.\n",
    "        ':REFC:'         Composite Reflectivity\n",
    "        ':surface:'      All variables at the surface.\n",
    "        ================ ===============================================    \n",
    "        \n",
    "    SAVEDIR : string\n",
    "        Directory path to save the file, default is the current directory.\n",
    "    dryrun : bool\n",
    "        If True, do not actually download, but print out what the function will\n",
    "        attempt to do.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The path and name of the new file.\n",
    "    \"\"\"\n",
    "    # Ping Pando first. This *might* prevent a \"bad handshake\" error.\n",
    "    if 'pando' in url:\n",
    "        try:\n",
    "            requests.head('https://pando-rgw01.chpc.utah.edu/')\n",
    "        except:\n",
    "            print('bad handshake...am I able to on?')\n",
    "            pass\n",
    "    \n",
    "    # Make SAVEDIR if path doesn't exist\n",
    "    if not os.path.exists(SAVEDIR):\n",
    "        os.makedirs(SAVEDIR)\n",
    "        print(f'Created directory: {SAVEDIR}')\n",
    "\n",
    "    \n",
    "    # Make a request for the .idx file for the above URL\n",
    "    idx = url + '.idx'\n",
    "    r = requests.get(idx)\n",
    "\n",
    "    # Check that the file exists. If there isn't an index, you will get a 404 error.\n",
    "    if not r.ok: \n",
    "        print('‚ùå SORRY! Status Code:', r.status_code, r.reason)\n",
    "        print(f'‚ùå It does not look like the index file exists: {idx}')\n",
    "\n",
    "    # Read the text lines of the request\n",
    "    lines = r.text.split('\\n')\n",
    "    \n",
    "    # Search expression\n",
    "    expr = re.compile(searchString)\n",
    "\n",
    "    # Store the byte ranges in a dictionary\n",
    "    #     {byte-range-as-string: line}\n",
    "    byte_ranges = {}\n",
    "    for n, line in enumerate(lines, start=1):\n",
    "        # n is the line number (starting from 1) so that when we call for \n",
    "        # `lines[n]` it will give us the next line. (Clear as mud??)\n",
    "\n",
    "        # Use the compiled regular expression to search the line\n",
    "        if expr.search(line):   \n",
    "            # aka, if the line contains the string we are looking for...\n",
    "\n",
    "            # Get the beginning byte in the line we found\n",
    "            parts = line.split(':')\n",
    "            rangestart = int(parts[1])\n",
    "\n",
    "            # Get the beginning byte in the next line...\n",
    "            if n+1 < len(lines):\n",
    "                # ...if there is a next line\n",
    "                parts = lines[n].split(':')\n",
    "                rangeend = int(parts[1])\n",
    "            else:\n",
    "                # ...if there isn't a next line, then go to the end of the file.\n",
    "                rangeend = ''\n",
    "\n",
    "            # Store the byte-range string in our dictionary, \n",
    "            # and keep the line information too so we can refer back to it.\n",
    "            byte_ranges[f'{rangestart}-{rangeend}'] = line\n",
    "    \n",
    "    # What should we name the file we save this data to?\n",
    "    # Let's name it something like `subset_20200624_hrrr.t01z.wrfsfcf17.grib2`\n",
    "    runDate = list(byte_ranges.items())[0][1].split(':')[2][2:-2]\n",
    "    outFile = '_'.join(['subset', runDate, url.split('/')[-1]])\n",
    "    outFile = os.path.join(SAVEDIR, outFile)\n",
    "    \n",
    "    for i, (byteRange, line) in enumerate(byte_ranges.items()):\n",
    "        \n",
    "        if i == 0:\n",
    "            # If we are working on the first item, overwrite the existing file.\n",
    "            curl = f'curl -s --range {byteRange} {url} > {outFile}'\n",
    "        else:\n",
    "            # If we are working on not the first item, append the existing file.\n",
    "            curl = f'curl -s --range {byteRange} {url} >> {outFile}'\n",
    "            \n",
    "        num, byte, date, var, level, forecast, _ = line.split(':')\n",
    "        \n",
    "        if dryrun:\n",
    "            print(f'  üåµ Dry Run: Found GRIB line [{num}]: variable={var}, level={level}, forecast={forecast}')\n",
    "            print(f'  üåµ Dry Run: `{curl}`')\n",
    "        else:\n",
    "            print(f'  Downloading GRIB line [{num}]: variable={var}, level={level}, forecast={forecast}')    \n",
    "            os.system(curl)\n",
    "    \n",
    "    if dryrun:\n",
    "        print(f'üåµ Dry Run: Success! Searched for [{searchString}] and found [{len(byte_ranges)}] GRIB fields.')\n",
    "        print(f'üåµ Dry Run: Would save as {outFile}')\n",
    "    else:\n",
    "        print(f'‚úÖ Success! Searched for [{searchString}] and got [{len(byte_ranges)}] GRIB fields.')\n",
    "        print(f'    Saved as {outFile}')\n",
    "    \n",
    "        return outFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading GRIB line [9]: variable=UGRD, level=250 mb, forecast=17 hour fcst\n",
      "  Downloading GRIB line [11]: variable=UGRD, level=300 mb, forecast=17 hour fcst\n",
      "  Downloading GRIB line [16]: variable=UGRD, level=500 mb, forecast=17 hour fcst\n",
      "  Downloading GRIB line [21]: variable=UGRD, level=700 mb, forecast=17 hour fcst\n",
      "  Downloading GRIB line [26]: variable=UGRD, level=850 mb, forecast=17 hour fcst\n",
      "  Downloading GRIB line [30]: variable=UGRD, level=925 mb, forecast=17 hour fcst\n",
      "  Downloading GRIB line [34]: variable=UGRD, level=1000 mb, forecast=17 hour fcst\n",
      "  Downloading GRIB line [55]: variable=UGRD, level=80 m above ground, forecast=17 hour fcst\n",
      "  Downloading GRIB line [71]: variable=UGRD, level=10 m above ground, forecast=17 hour fcst\n",
      "‚úÖ Success! Searched for [:UGRD:] and got [9] GRIB fields.\n",
      "    Saved as ./subset_20200624_hrrr.t01z.wrfsfcf17.grib2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./subset_20200624_hrrr.t01z.wrfsfcf17.grib2'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download u-component wind speeds at all available levels\n",
    "download_HRRR_subset(url, ':UGRD:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:0:d=2020062401:UGRD:250 mb:17 hour fcst:\n",
      "2:780694:d=2020062401:UGRD:300 mb:17 hour fcst:\n",
      "3:1569249:d=2020062401:UGRD:500 mb:17 hour fcst:\n",
      "4:2160862:d=2020062401:UGRD:700 mb:17 hour fcst:\n",
      "5:2766500:d=2020062401:UGRD:850 mb:17 hour fcst:\n",
      "6:3392321:d=2020062401:UGRD:925 mb:17 hour fcst:\n",
      "7:4028858:d=2020062401:UGRD:1000 mb:17 hour fcst:\n",
      "8:4662733:d=2020062401:UGRD:80 m above ground:17 hour fcst:\n",
      "9:5857789:d=2020062401:UGRD:10 m above ground:17 hour fcst:\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wgrib2 ./subset_20200624_hrrr.t01z.wrfsfcf17.grib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading GRIB line [14]: variable=TMP, level=500 mb, forecast=17 hour fcst\n",
      "  Downloading GRIB line [15]: variable=DPT, level=500 mb, forecast=17 hour fcst\n",
      "  Downloading GRIB line [19]: variable=TMP, level=700 mb, forecast=17 hour fcst\n",
      "  Downloading GRIB line [20]: variable=DPT, level=700 mb, forecast=17 hour fcst\n",
      "‚úÖ Success! Searched for [:(TMP|DPT|RH):(500|700) mb] and got [4] GRIB fields.\n",
      "    Saved as ./subset_20200624_hrrr.t01z.wrfsfcf17.grib2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./subset_20200624_hrrr.t01z.wrfsfcf17.grib2'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download TMP, DPT, and RH at 500 mb and 700 mb\n",
    "download_HRRR_subset(url, ':(TMP|DPT|RH):(500|700) mb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:0:d=2020062401:TMP:500 mb:17 hour fcst:\n",
      "2:545502:d=2020062401:DPT:500 mb:17 hour fcst:\n",
      "3:1544471:d=2020062401:TMP:700 mb:17 hour fcst:\n",
      "4:2109950:d=2020062401:DPT:700 mb:17 hour fcst:\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wgrib2 ./subset_20200624_hrrr.t01z.wrfsfcf17.grib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading GRIB line [71]: variable=UGRD, level=10 m above ground, forecast=17 hour fcst\n",
      "  Downloading GRIB line [72]: variable=VGRD, level=10 m above ground, forecast=17 hour fcst\n",
      "‚úÖ Success! Searched for [:.GRD:10 m] and got [2] GRIB fields.\n",
      "    Saved as ./subset_20200624_hrrr.t01z.wrfsfcf17.grib2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./subset_20200624_hrrr.t01z.wrfsfcf17.grib2'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download u- and v-component wind at 10 m above ground\n",
    "download_HRRR_subset(url, ':.GRD:10 m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:0:d=2020062401:UGRD:10 m above ground:17 hour fcst:\n",
      "2:1200967:d=2020062401:VGRD:10 m above ground:17 hour fcst:\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wgrib2 ./subset_20200624_hrrr.t01z.wrfsfcf17.grib2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a \"dryrun\" option, so you can see what the function will do before actually downloading anything. This is useful for testing and developing new searches to make sure it will grab the files you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  üåµ Dry Run: Found GRIB line [57]: variable=PRES, level=surface, forecast=17 hour fcst\n",
      "  üåµ Dry Run: `curl -s --range 35543182-37123359 https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2 > ./subset_20200624_hrrr.t01z.wrfsfcf17.grib2`\n",
      "  üåµ Dry Run: Found GRIB line [105]: variable=PRES, level=cloud base, forecast=17 hour fcst\n",
      "  üåµ Dry Run: `curl -s --range 68756586-69497618 https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2 >> ./subset_20200624_hrrr.t01z.wrfsfcf17.grib2`\n",
      "  üåµ Dry Run: Found GRIB line [108]: variable=PRES, level=cloud top, forecast=17 hour fcst\n",
      "  üåµ Dry Run: `curl -s --range 72384572-73069096 https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2 >> ./subset_20200624_hrrr.t01z.wrfsfcf17.grib2`\n",
      "  üåµ Dry Run: Found GRIB line [128]: variable=PRES, level=0C isotherm, forecast=17 hour fcst\n",
      "  üåµ Dry Run: `curl -s --range 105295600-105996495 https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2 >> ./subset_20200624_hrrr.t01z.wrfsfcf17.grib2`\n",
      "  üåµ Dry Run: Found GRIB line [131]: variable=PRES, level=highest tropospheric freezing level, forecast=17 hour fcst\n",
      "  üåµ Dry Run: `curl -s --range 107459777-108159837 https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2 >> ./subset_20200624_hrrr.t01z.wrfsfcf17.grib2`\n",
      "üåµ Dry Run: Success! Searched for [:PRES:] and found [5] GRIB fields.\n",
      "üåµ Dry Run: Would save as ./subset_20200624_hrrr.t01z.wrfsfcf17.grib2\n"
     ]
    }
   ],
   "source": [
    "# Download u- and v-component wind at 10 m above ground\n",
    "download_HRRR_subset(url, ':PRES:', dryrun=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "#### Notes\n",
    "\n",
    "I was looking for a non-curl method to download, but couldn't find one. I have not found a way to download a range of bytes with the `requests` library. Primarily because `requests` canot do a `seek` on the GRIB2 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnsupportedOperation",
     "evalue": "seek",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnsupportedOperation\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8a908766abae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Move stream to the firt byte we want\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_byte\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnsupportedOperation\u001b[0m: seek"
     ]
    }
   ],
   "source": [
    "url = 'https://pando-rgw01.chpc.utah.edu/hrrr/sfc/20200624/hrrr.t01z.wrfsfcf17.grib2'\n",
    "r = requests.get(url, stream=True)\n",
    "\n",
    "# Range of bytes I want\n",
    "start_byte = 11260176\n",
    "end_byte = 17825413\n",
    "\n",
    "# Move stream to the firt byte we want\n",
    "r.raw.seek(start_byte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But I can read from the begining of the file to a byte, but this isn't helpful for just getting a GRIB message from the middle of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "r = requests.get(url, stream=True)\n",
    "\n",
    "with open('smallFile.grib2', 'wb') as f:\n",
    "    f.write(io.BytesIO(r.raw.read(end_byte)).getbuffer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:0:d=2020062401:REFC:entire atmosphere:17 hour fcst:\n",
      "2:490289:d=2020062401:RETOP:cloud top:17 hour fcst:\n",
      "3:681173:d=2020062401:VIL:entire atmosphere:17 hour fcst:\n",
      "4:943024:d=2020062401:VIS:surface:17 hour fcst:\n",
      "5:2286009:d=2020062401:REFD:1000 m above ground:17 hour fcst:\n",
      "6:2547950:d=2020062401:REFD:4000 m above ground:17 hour fcst:\n",
      "7:2723918:d=2020062401:REFD:263 K level:17 hour fcst:\n",
      "8:2901079:d=2020062401:GUST:surface:17 hour fcst:\n",
      "9:4074410:d=2020062401:UGRD:250 mb:17 hour fcst:\n",
      "10:4855103:d=2020062401:VGRD:250 mb:17 hour fcst:\n",
      "11:5621119:d=2020062401:UGRD:300 mb:17 hour fcst:\n",
      "12:6409673:d=2020062401:VGRD:300 mb:17 hour fcst:\n",
      "13:7182342:d=2020062401:HGT:500 mb:17 hour fcst:\n",
      "14:7852240:d=2020062401:TMP:500 mb:17 hour fcst:\n",
      "15:8397741:d=2020062401:DPT:500 mb:17 hour fcst:\n",
      "16:9396709:d=2020062401:UGRD:500 mb:17 hour fcst:\n",
      "17:9988321:d=2020062401:VGRD:500 mb:17 hour fcst:\n",
      "18:10587398:d=2020062401:HGT:700 mb:17 hour fcst:\n",
      "19:11260176:d=2020062401:TMP:700 mb:17 hour fcst:\n",
      "20:11825654:d=2020062401:DPT:700 mb:17 hour fcst:\n",
      "21:12910456:d=2020062401:UGRD:700 mb:17 hour fcst:\n",
      "22:13516093:d=2020062401:VGRD:700 mb:17 hour fcst:\n",
      "23:14130774:d=2020062401:HGT:850 mb:17 hour fcst:\n",
      "24:14834021:d=2020062401:TMP:850 mb:17 hour fcst:\n",
      "25:15422699:d=2020062401:DPT:850 mb:17 hour fcst:\n",
      "26:16569914:d=2020062401:UGRD:850 mb:17 hour fcst:\n",
      "27:17195734:d=2020062401:VGRD:850 mb:17 hour fcst:\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wgrib2 smallFile.grib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
